# -*- coding: utf-8 -*-
"""Deepfake Detection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1owXWAvWZjvJLpDjkp2vCO9lhg5bs8qKI
"""

# Commented out IPython magic to ensure Python compatibility.
# %pip install torchview

!pip install opendatasets

import opendatasets as od
od.download("https://www.kaggle.com/datasets/saurabhbagchi/deepfake-image-detection")

# PyTorch tools
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import TensorDataset, DataLoader, Dataset
import torchvision.transforms as transforms
from torchvision import models, Module
from torchsummary import summary
from torchview import draw_graph

# Common tools
import pandas as pd
import numpy as np
import os
import matplotlib.pyplot as plt
import seaborn as sns
import torch
import torchvision.transforms as transforms
from torch.utils.data import Dataset, DataLoader


# Sklearn tools
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

# opencv tools
import cv2

base_dirs = [
    "/content/deepfake-image-detection/test-20250112T065939Z-001",
    "/content/deepfake-image-detection/train-20250112T065955Z-001"
]

import os

for base_dir in base_dirs:
    if os.path.exists(base_dir):
        print(f"‚úÖ Path exists: {base_dir}")
    else:
        print(f"‚ùå Path NOT found: {base_dir}")

"""Loading the dataset

"""

# Given train & test sets
g_train = {"fake": [], "real": []}
g_test  = {"fake": [], "real": []}

# Base directories
base_dirs = [
    "/content/deepfake-image-detection/test-20250112T065939Z-001",
    "/content/deepfake-image-detection/train-20250112T065955Z-001"
]

# Labels
labels = ["fake", "real"]

# Read the images
for base_dir in base_dirs:
    for label in labels:
        # Construct the image directory path
        img_dir = os.path.join(base_dir, "train" if "train" in base_dir else "test", label)

        # List all files in the directory and construct full paths
        files = [os.path.join(img_dir, x) for x in os.listdir(img_dir)]

        # Append files to the appropriate dictionary
        if "train" in base_dir:
          g_train[label] += files
        else:
            g_test[label] += files
print("Done!")

# merge all images and labels accordingly
all_images = []
all_labels = []
for label in labels:
    all_images += g_train[label] + g_test[label]
    all_labels += [label]*len(g_train[label]) + [label]*len(g_test[label])

print("Done!")

Images = []
Labels = []

# Create the 'data' DataFrame
data = pd.DataFrame({"images": all_images, "labels": all_labels})

for i in range(len(data)):
    image_path = data['images'][i]
    label = data['labels'][i]
    try:
        img = cv2.imread(image_path)

        if img is None or img.size == 0:  # Check if the image is empty or corrupt
            raise ValueError(f"Corrupt or empty image: {image_path}")

        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB

        Images.append(img)
        Labels.append(label)

    except Exception as e:
        print(f"‚ö† Error loading image {image_path}: {e}")

print(f"‚úÖ Total valid images: {len(Images)}, Total valid labels: {len(Labels)}")

"""## Exploratory Data Analysis"""

# Display basic statistics of the dataset
print("üìä Basic Statistics:")
print(data.describe())  # Summary of numerical columns

# Check class distribution
print("\nüîç Class Distribution:")
print(data['labels'].value_counts())

# Check for duplicates
print("\nüõ† Checking for Duplicates...")
print(f"Duplicate Entries: {data.duplicated().sum()}")

# Check for missing values
print("\n‚ö† Checking for Missing Values...")
print(data.isnull().sum())

print(len(all_images), len(all_labels))  # Both should be equal
print(all_images[:5], all_labels[:5])  # See first 5 images & labels

# display the tables
data = pd.DataFrame({"images": all_images, "labels":all_labels})
display(data)

# for better randomization, shuffles the data
data = data.sample(frac=1, random_state=42)  # Shuffle in place
data.reset_index(drop=True, inplace=True)  # Reset index in place

# Display the shuffled DataFrame
display(data)

# convert the labels into numeric formate
label_map = {'fake': 0, 'real':1}
# apply into the table
data['labels'] = data['labels'].map(label_map)
# Display the updated DataFrame
display(data)

"""Reading the images"""

max_height = float('-inf')
min_height = float('inf')
max_width = float('-inf')
min_width = float('inf')

for i in range(len(data)):
    image_path = data['images'][i]
    try:
        img = cv2.imread(image_path)
        if img is None:
            raise FileNotFoundError(f"Image not found: {image_path}")

        # Track min and max dimensions
        max_height = max(max_height, img.shape[0])
        min_height = min(min_height, img.shape[0])
        max_width = max(max_width, img.shape[1])
        min_width = min(min_width, img.shape[1])

    except Exception as e:
        print(f"Error: {e}")

print(f"üìä Max Height: {max_height}, Min Height: {min_height}")
print(f"üìä Max Width: {max_width}, Min Width: {min_width}")

"""Visualizing the Images"""

# Visualize some images
# number of images
num_imgs = 20
ncols = 4
nrows = (num_imgs + ncols - 1) // ncols
# Create a figure to display the images
plt.figure(figsize=(15, 10))
for i, img in enumerate(Images[:num_imgs]):
    plt.subplot(nrows, ncols, i+1)
    plt.imshow(img)
    plt.title(f"Label: {Labels[i]}")
    plt.axis('off')
plt.show()

# Create a count plot
sns.countplot(x=np.array(y_train))

# Add labels and title
plt.xlabel("Class")
plt.ylabel("Count")
plt.title("Distribution of Classes in Training Set")

# Show the plot
plt.show()

from imblearn.over_sampling import RandomOverSampler

# Handle class imbalance if needed
ros = RandomOverSampler(random_state=42)
X_train_resampled, y_train_resampled = ros.fit_resample(np.array(X_train).reshape(len(X_train), -1), np.array(y_train))

# Check new class distribution
sns.countplot(x=y_train_resampled)
plt.xlabel("Class")
plt.ylabel("Count")
plt.title("Balanced Class Distribution after Oversampling")
plt.show()

"""# Preprocessing

Distribution of images before resizing
"""

# Print original image shapes before resizing
image_shapes = [img.shape for img in Images]
heights = [h for h, w, c in image_shapes]
widths = [w for h, w, c in image_shapes]

print(f"üìè Mean Image Height: {np.mean(heights)}, Width: {np.mean(widths)}")
print(f"üìè Median Image Height: {np.median(heights)}, Width: {np.median(widths)}")
print(f"üìè Standard Deviation of Height: {np.std(heights)}, Width: {np.std(widths)}")

# Visualizing image size distribution
plt.figure(figsize=(10, 5))
sns.histplot(heights, kde=True, color="blue", label="Height")
sns.histplot(widths, kde=True, color="red", label="Width")
plt.legend()
plt.title("Distribution of Image Dimensions Before Resizing")
plt.show()

"""Resizing the Images"""

# resize the images
target_size = (224,224)
Images_resize = [cv2.resize(img, target_size) for img in Images]

# Visualize some images
# number of images
num_imgs = 20
ncols = 4
nrows = (num_imgs + ncols - 1) // ncols
# Create a figure to display the images
plt.figure(figsize=(15, 10))
for i, img in enumerate(Images_resize[:num_imgs]):
    plt.subplot(nrows, ncols, i+1)
    plt.imshow(img)
    plt.title(f"Label: {Labels[i]}")
    plt.axis('off')
plt.show()

"""Splitting into Train/Test/Validation"""

# Step 1: Split into 95% training and 5% testing
X_train, X_test, y_train, y_test = train_test_split(Images_resize, Labels, test_size=0.05, random_state=42)

# Step 2: Split the training set into 95% training and 5% validation
X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.05, random_state=42)

# Step 5: Verify the shapes of the generators
print("Training data shape:", len(X_train))
print("Validation data shape:", len(X_val))
print("Testing data shape:", len(X_test))

"""Data Augmentation"""

from tensorflow.keras.preprocessing.image import ImageDataGenerator
import numpy as np
import matplotlib.pyplot as plt

# Define augmentation
datagen = ImageDataGenerator(
    rotation_range=20,
    width_shift_range=0.1,
    height_shift_range=0.1,
    horizontal_flip=True
)

# Show example images before and after augmentation
fig, axes = plt.subplots(2, 5, figsize=(15, 6))

for i in range(5):
    img = X_train[i]  # Original image

    # Ensure the image is correctly formatted for augmentation
    augmented_img = datagen.flow(np.expand_dims(img, axis=0), batch_size=1).__next__()[0].astype('uint8')

    # Display original
    axes[0, i].imshow(img)
    axes[0, i].set_title("Original")
    axes[0, i].axis("off")

    # Display augmented
    axes[1, i].imshow(augmented_img)
    axes[1, i].set_title("Augmented")
    axes[1, i].axis("off")

plt.suptitle("Before and After Data Augmentation", fontsize=14)
plt.show()

"""# Custom dataset"""

# Define Transformations: Augment First, Then Normalize
transform = transforms.Compose([
    transforms.ToPILImage(),  # Convert OpenCV (NumPy) image to PIL format
    transforms.RandomHorizontalFlip(),
    transforms.RandomRotation(10),
    transforms.ToTensor(),  # Convert to Tensor [0,1], normalized pixel
])

class CustomImageDataset(Dataset):
    def __init__(self, images, labels, transform=None):
        """
        images: List of NumPy arrays (H, W, C)
        labels: List or NumPy array of shape (N,)
        transform: Augmentation transformations
        """
        self.images = np.array(images)  # Keep as NumPy array, apply transforms later
        # Convert labels to numerical format
        label_mapping = {'fake': 0, 'real': 1}
        self.labels = torch.tensor(np.array([label_mapping[label] for label in labels]), dtype=torch.long)
        self.transform = transform  # Store the transform function

    def __len__(self):
        return len(self.images)
    def __getitem__(self, idx):
        image = self.images[idx]

        if self.transform:
            image = self.transform(image)  # Apply augmentations

        label = self.labels[idx]
        return image, label

# Create dataset and DataLoader
train_dataset = CustomImageDataset(X_train, y_train, transform=transform)
train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)
val_dataset = CustomImageDataset(X_val, y_val, transform=transform)
val_dataloader = DataLoader(val_dataset, batch_size=64, shuffle=True)

# Fetch one batch
images, labels = next(iter(train_dataloader))
print(images.shape)  # Expected: [batch_size, 3, H, W]
print(labels)

"""# Train Model:"""

# Load the pretrained model
model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V2)

# Freeze all layers except the last ones
for param in model.parameters():
    param.requires_grad = False  # Unfreeze all layers

# Modify the fully connected (FC) layer
num_ftrs = model.fc.in_features
model.fc = nn.Sequential(
    nn.Linear(num_ftrs, 1024),  # First fully connected layer
    nn.BatchNorm1d(1024),       # Batch Normalization
    nn.LeakyReLU(),             # Activation function
    nn.Dropout(0.5),            # Dropout for regularization

    nn.Linear(1024, 512),       # Second fully connected layer
    nn.BatchNorm1d(512),        # Batch Normalization
    nn.LeakyReLU(),             # Activation function
    nn.Dropout(0.5),            # Dropout for regularization

    nn.Linear(512, 1),          # Final fully connected layer
    nn.Sigmoid()                # Sigmoid activation for binary classification
)

# Move model to GPU if available
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = model.to(device)

# Define Loss Function & Optimizer
criterion = nn.BCELoss()  # Binary Cross Entropy Loss
optimizer = optim.Adam(model.parameters(), lr=0.0001)

# Define Accuracy Function
def binary_accuracy(preds, labels):
    preds = (preds >= 0.5).float()  # Convert probabilities to binary (0 or 1)
    return (preds == labels).sum().item() / labels.size(0)

# Adaptive Learning Rate Scheduler (Reduce LR if val_loss does not improve for 3 epochs)
scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=3, factor=0.5)

# Training Function
def train(model, train_loader, val_loader, criterion, optimizer, scheduler, epochs=10, save_path="best_model.pth"):
    best_val_loss = float('inf')
    for epoch in range(epochs):
        model.train()
        train_loss, train_acc = 0.0, 0.0

        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device).float().unsqueeze(1)  # Ensure labels are float
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

            train_loss += loss.item()
            train_acc += binary_accuracy(outputs, labels)

        # Validation
        model.eval()
        val_loss, val_acc = 0.0, 0.0
        with torch.no_grad():
            for images, labels in val_loader:
                images, labels = images.to(device), labels.to(device).float().unsqueeze(1)

                outputs = model(images)
                loss = criterion(outputs, labels)

                val_loss += loss.item()
                val_acc += binary_accuracy(outputs, labels)
        # Reduce LR if validation loss does not improve
        scheduler.step(val_loss)

        # Save Best Model (Based on Validation Loss)
        if val_loss < best_val_loss:
            best_val_loss = val_loss
            print(f"Saving the Model with loss{best_val_loss}")
            torch.save(model.state_dict(), save_path)
        # Get the current learning rate
        current_lr = optimizer.param_groups[0]['lr']
        # Print Training and Validation Metrics
        print(f"Epoch {epoch+1}/{epochs} | "
              f"Train Loss: {train_loss/len(train_loader):.4f}, Train Acc: {train_acc/len(train_loader):.4f} | "
              f"Val Loss: {val_loss/len(val_loader):.4f}, Val Acc: {val_acc/len(val_loader):.4f} | "
              f"LR: {current_lr:.6f}")

# training
train(model, train_dataloader, val_dataloader, criterion, optimizer, scheduler, epochs=100, save_path="best_resnet50.pth")

"""# Performance on Test Data:"""

test_transform = transforms.Compose([
    transforms.ToPILImage(),  # Convert OpenCV (NumPy) image to PIL format
    transforms.ToTensor(),  # Convert to Tensor [0,1], normalized pixel
])
test_dataset = CustomImageDataset(X_test, y_test, transform=test_transform)
test_dataloader = DataLoader(test_dataset, batch_size=len(X_test), shuffle=False)
# Validation
model.eval()
val_acc = 0.0
with torch.no_grad():
    for images, labels in test_dataloader:
        images, labels = images.to(device), labels.to(device).float().unsqueeze(1)

        outputs = model(images)
        val_acc += binary_accuracy(outputs, labels)
print(f"Resnet Test Accuracy: {val_acc}")

def plot_test_images(image_list, labels, preds, class_names, num_images=10):
    """
    image_list: List of test images (NumPy arrays in [H, W, C] format).
    labels: List or array of actual labels.
    preds: List or array of predicted labels.
    class_names: Dictionary or list mapping label indices to class names.
    num_images: Number of images to display.
    """
    num_images = min(num_images, len(image_list))  # Ensure we don't exceed available images
    ncols = 5
    nrows = int(np.ceil(num_images / ncols))  # Round up rows to fit all images

    fig, axes = plt.subplots(nrows, ncols, figsize=(10, 30))
    axes = axes.flatten()

    for i in range(num_images):
        img = image_list[i]  # Get image
        actual_label = class_names[labels[i]]
        predicted_label = class_names[1 if preds[i] >= 0.5 else 0]
        axes[i].imshow(img)
        axes[i].set_title(f"Actual: {actual_label}\nPred: {predicted_label}", fontsize=10)
        axes[i].axis("off")
    # Hide unused subplots (if any)
    for i in range(num_images, len(axes)):
        axes[i].axis("off")
    plt.tight_layout()
    plt.show()
# Convert labels from strings to numeric format
label_mapping = {'fake': 0, 'real': 1}
y_test_numeric = [label_mapping[label] for label in y_test]

plot_test_images(image_list=X_test, labels=y_test_numeric, preds=outputs, class_names={0: "fake", 1: "real"}, num_images=len(X_test))

"""# Using EfficientNet"""

!pip install efficientnet_pytorch

import torch

from efficientnet_pytorch import EfficientNet
import torch.nn as nn

# Load pretrained EfficientNet-B0
model = EfficientNet.from_pretrained('efficientnet-b0')

# Modify the final layer for binary classification
num_features = model._fc.in_features
model._fc = nn.Sequential(
    nn.Linear(num_features, 512),
    nn.ReLU(),
    nn.Dropout(0.4),
    nn.Linear(512, 1)  # <-- No sigmoid here!
)

#Loss Function
criterion = nn.BCEWithLogitsLoss()


# Define the device (GPU or CPU)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Move to device
model = model.to(device)

import torch.optim as optim # import the optim module

optimizer = optim.Adam(model.parameters(), lr=0.0001)
scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=3, factor=0.5)

"""Train Model"""

train(model, train_dataloader, val_dataloader, criterion, optimizer, scheduler, epochs=100, save_path="best_efficientnet.pth")

"""# Performance on Test Data"""

from torchvision import transforms

test_transform = transforms.Compose([
    transforms.ToPILImage(),
    transforms.Resize((224, 224)),  # EfficientNetB0 input size
    transforms.ToTensor(),
])

test_dataset = CustomImageDataset(X_test, y_test, transform=test_transform)
test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)

# Define accuracy function (outside loop)
def binary_accuracy(preds, labels):
    preds = (preds >= 0.5).float()  # Convert probabilities to binary predictions
    return (preds == labels).sum().item() / labels.size(0)

# Evaluation on test data
model.eval()
test_acc = 0.0
outputs_list = []

with torch.no_grad():
    for images, labels in test_dataloader:
        images, labels = images.to(device), labels.to(device).float().unsqueeze(1)
        outputs = model(images)

        # Accumulate accuracy
        test_acc += binary_accuracy(outputs, labels)
        outputs_list.extend(outputs.cpu().numpy().flatten())

# Normalize test accuracy
test_acc /= len(test_dataloader)

print(f"EfficientNet Test Accuracy: {test_acc:.4f}")

# Step 1: Convert string labels to numeric (if needed)
label_mapping = {'fake': 0, 'real': 1}
y_test_numeric = np.array([label_mapping[label] if isinstance(label, str) else label for label in y_test])

# Step 2: Define the plot_test_images function
def plot_test_images(image_list, labels, preds, class_names, num_images=10):
    """
    image_list: List of test images (NumPy arrays in [H, W, C] format).
    labels: List or array of actual labels (numeric).
    preds: List or array of predicted probabilities or binary labels.
    class_names: Dict mapping label indices to class names.
    num_images: Number of images to display.
    """
    num_images = min(num_images, len(image_list))  # Limit number of images to display
    ncols = 5
    nrows = int(np.ceil(num_images / ncols))  # Rows to fit all images

    fig, axes = plt.subplots(nrows, ncols, figsize=(15, 10))
    axes = axes.flatten()

    for i in range(num_images):
        img = image_list[i]
        actual_label = class_names[int(labels[i])]
        predicted_label = class_names[1 if preds[i] >= 0.5 else 0]
        axes[i].imshow(img)
        axes[i].set_title(f"Actual: {actual_label}\nPred: {predicted_label}", fontsize=9)
        axes[i].axis("off")

    for i in range(num_images, len(axes)):
        axes[i].axis("off")  # Hide unused axes
    plt.tight_layout()
    plt.show()

# Step 3: Plot
plot_test_images(
    image_list=X_test,
    labels=y_test_numeric,
    preds=outputs_list,
    class_names={0: "fake", 1: "real"},
    num_images=15  # You can increase this if needed
)

# Assuming 'val_acc' from the ResNet50 evaluation section holds the accuracy
resnet_test_acc = 0.8163 # Store ResNet50's test accuracy

# Assign the EfficientNet test accuracy from the previous cell output
efficientnet_test_acc = 0.8631   # 'test_acc' from the EfficientNet evaluation

print(f"Resnet50 Test Accuracy: {resnet_test_acc:.4f}")
print(f"EfficientNet Test Accuracy: {efficientnet_test_acc:.4f}")

if efficientnet_test_acc > resnet_test_acc:
    print("‚úÖ EfficientNet performs better.")
else:
    print("‚úÖ ResNet50 performs better.")

# Only save the one that performed better
best_model_path = "best_model.pth"  # Could be "best_resnet50.pth" or "best_efficientnet.pth"
torch.save(model.state_dict(), best_model_path)
print(f"Best model saved to {best_model_path}")

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
import numpy as np
import matplotlib.pyplot as plt

# Convert labels to numeric if they are strings
label_mapping = {'fake': 0, 'real': 1}
y_test_numeric = np.array([label_mapping[label] if isinstance(label, str) else label for label in y_test])

def plot_conf_matrix(labels, preds, class_names={0: "fake", 1: "real"}):
    binary_preds = (np.array(preds) >= 0.5).astype(int)
    labels = np.array(labels)

    cm = confusion_matrix(labels, binary_preds)
    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[class_names[0], class_names[1]])
    disp.plot(cmap=plt.cm.Blues)
    plt.title("Confusion Matrix")
    plt.grid(False)
    plt.show()

# Call the function
plot_conf_matrix(y_test_numeric, outputs_list)